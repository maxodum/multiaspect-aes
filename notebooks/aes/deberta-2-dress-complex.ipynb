{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11496551,"sourceType":"datasetVersion","datasetId":7110184},{"sourceId":11840206,"sourceType":"datasetVersion","datasetId":7439072}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch datasets scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:40.424326Z","iopub.execute_input":"2025-05-17T19:41:40.424670Z","iopub.status.idle":"2025-05-17T19:41:43.684655Z","shell.execute_reply.started":"2025-05-17T19:41:40.424637Z","shell.execute_reply":"2025-05-17T19:41:43.683887Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import BertTokenizer\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom transformers import AutoModel, AutoTokenizer\nfrom datasets import load_dataset\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:43.686042Z","iopub.execute_input":"2025-05-17T19:41:43.686280Z","iopub.status.idle":"2025-05-17T19:41:49.004715Z","shell.execute_reply.started":"2025-05-17T19:41:43.686257Z","shell.execute_reply":"2025-05-17T19:41:49.004066Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/dress-d/train.csv', index_col=0)\nval_df = pd.read_csv('/kaggle/input/dress-d/val.csv', index_col=0)\ntest_df = pd.read_csv('/kaggle/input/dress-d/test.csv', index_col=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:49.005765Z","iopub.execute_input":"2025-05-17T19:41:49.006376Z","iopub.status.idle":"2025-05-17T19:41:49.188810Z","shell.execute_reply.started":"2025-05-17T19:41:49.006349Z","shell.execute_reply":"2025-05-17T19:41:49.188024Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class EllipseDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.df = dataframe\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        text = row[\"full_text\"].to_list()\n\n\n\n        scores = torch.tensor(row[[\"Overall\",\n                                   \"Cohesion\",\n                                   \"Syntax\",\n                                   \"Vocabulary\",\n                                   \"Phraseology\",\n                                   \"Grammar\",\n                                   \"Conventions\"]\n                                  ].values, dtype=torch.float32)\n\n\n        inputs = self.tokenizer(text,\n                                padding=\"max_length\",\n                                truncation=True,\n                                return_tensors=\"pt\",\n                                max_length=512)\n\n\n\n        return {\n            \"input_ids\": inputs[\"input_ids\"],\n            \"attention_mask\": inputs[\"attention_mask\"],\n            \"scores\": scores\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:49.190359Z","iopub.execute_input":"2025-05-17T19:41:49.190603Z","iopub.status.idle":"2025-05-17T19:41:49.196275Z","shell.execute_reply.started":"2025-05-17T19:41:49.190585Z","shell.execute_reply":"2025-05-17T19:41:49.195400Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\", use_fast=False)\nspecial_token = \"\\n\\n\"\ntokenizer.add_special_tokens({'additional_special_tokens': [special_token]})\n\ntrain_dataset = EllipseDataset(train_df.reset_index(drop=True), tokenizer)\nval_dataset = EllipseDataset(val_df.reset_index(drop=True), tokenizer)\ntest_dataset = EllipseDataset(test_df.reset_index(drop=True), tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:49.197020Z","iopub.execute_input":"2025-05-17T19:41:49.197191Z","iopub.status.idle":"2025-05-17T19:41:49.893246Z","shell.execute_reply.started":"2025-05-17T19:41:49.197178Z","shell.execute_reply":"2025-05-17T19:41:49.892172Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DebertaNHeads(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_aspects=7):\n        super().__init__()\n        self.deberta = AutoModel.from_pretrained(model_name)\n        self.deberta.resize_token_embeddings(len(tokenizer))\n        hidden_size = self.deberta.config.hidden_size\n\n        self.num_aspects = num_aspects\n        \n        self.regression_heads = nn.ModuleList([\n            nn.Linear(hidden_size, 1) for _ in range(num_aspects)\n        ])\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(0.2)\n        \n        self._init_weights()\n\n    def _init_weights(self):\n        for head in self.regression_heads:\n            init.xavier_uniform_(head.weight)\n            if head.bias is not None:\n                init.zeros_(head.bias)\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        regression_outputs = []\n\n        for i in range(self.num_aspects):\n            regression_outputs.append(self.sigmoid(self.regression_heads[i](pooled_output)))\n\n        regression_outputs = torch.cat(regression_outputs, dim=1)\n\n        return regression_outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:49.894149Z","iopub.execute_input":"2025-05-17T19:41:49.894397Z","iopub.status.idle":"2025-05-17T19:41:49.903708Z","shell.execute_reply.started":"2025-05-17T19:41:49.894375Z","shell.execute_reply":"2025-05-17T19:41:49.902930Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = DebertaNHeads()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:41:49.904368Z","iopub.execute_input":"2025-05-17T19:41:49.904632Z","iopub.status.idle":"2025-05-17T19:41:56.038399Z","shell.execute_reply.started":"2025-05-17T19:41:49.904606Z","shell.execute_reply":"2025-05-17T19:41:56.037616Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 19:41:51.583586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747510911.605750     125 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747510911.612467     125 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import get_scheduler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:00.222391Z","iopub.execute_input":"2025-05-17T19:42:00.223304Z","iopub.status.idle":"2025-05-17T19:42:00.232974Z","shell.execute_reply.started":"2025-05-17T19:42:00.223277Z","shell.execute_reply":"2025-05-17T19:42:00.232358Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)\ntest_loader = DataLoader(test_dataset, batch_size=8)\n\nnum_training_steps = len(train_loader) * 10\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noptimizer = optim.AdamW(model.parameters(), lr=4e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=num_training_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:01.545053Z","iopub.execute_input":"2025-05-17T19:42:01.545342Z","iopub.status.idle":"2025-05-17T19:42:01.860730Z","shell.execute_reply.started":"2025-05-17T19:42:01.545321Z","shell.execute_reply":"2025-05-17T19:42:01.860119Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def combined_loss(reg_preds, reg_labels):\n    regression_loss = nn.BCELoss()\n    total_reg_loss = 0\n    total_reg_loss += regression_loss(reg_preds, reg_labels)\n\n    return total_reg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:01.861934Z","iopub.execute_input":"2025-05-17T19:42:01.862209Z","iopub.status.idle":"2025-05-17T19:42:01.866556Z","shell.execute_reply.started":"2025-05-17T19:42:01.862186Z","shell.execute_reply":"2025-05-17T19:42:01.865815Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate_qwk_for_aspects(class_preds, class_labels, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions']):\n    class_preds = class_preds * 4 + 1\n    class_labels = class_labels * 4 + 1\n\n    class_preds = np.round(class_preds * 2) / 2\n    class_labels = np.round(class_labels * 2) / 2\n\n    class_preds = ((class_preds - 1) * 2).astype(int)\n    class_labels = ((class_labels - 1) * 2).astype(int)\n\n    qwk_scores = {}\n    for i, aspect in enumerate(aspects):\n        qwk_score = cohen_kappa_score(class_preds[:, i], class_labels[:, i], weights='quadratic')\n        qwk_scores[aspect] = qwk_score\n        print(f'QWK for {aspect}: {qwk_score:.4f}')\n\n    return qwk_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:03.436256Z","iopub.execute_input":"2025-05-17T19:42:03.436832Z","iopub.status.idle":"2025-05-17T19:42:03.442244Z","shell.execute_reply.started":"2025-05-17T19:42:03.436807Z","shell.execute_reply":"2025-05-17T19:42:03.441393Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"for layer in model.deberta.encoder.layer[:9]:\n    for param in layer.parameters():\n        param.requires_grad = False\nfor param in model.deberta.embeddings.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:03.967833Z","iopub.execute_input":"2025-05-17T19:42:03.968385Z","iopub.status.idle":"2025-05-17T19:42:03.972691Z","shell.execute_reply.started":"2025-05-17T19:42:03.968363Z","shell.execute_reply":"2025-05-17T19:42:03.971905Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_losses = []\nqwk_scores = []\nbest_qwk = -float('inf')\n\nmodel.train()\nfor epoch in range(10):\n    loss_per_epoch = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n\n    all_preds = []\n    all_targets = []\n\n    for batch in loop:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        reg_target = batch[\"scores\"].to(device)\n        reg_preds = model(input_ids, attention_mask)\n        loss = 0\n        for i in range(7):\n            loss += combined_loss(reg_preds[:, i], reg_target[:, i])\n        loss /= 7\n        loss_per_epoch += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = loss_per_epoch / len(train_loader)\n    train_losses.append(avg_loss)\n    print(f'Loss_per_epoch = {avg_loss}')\n\n    model.eval()\n    loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}\")\n    with torch.no_grad():\n        for batch in loop:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            reg_target = batch[\"scores\"].to(device)\n            reg_preds = model(input_ids, attention_mask)\n            all_preds.append(reg_preds)\n            all_targets.append(reg_target)\n    all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n    all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n    qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])\n    qwk_scores.append(qwk)\n    avg_qwk = sum(qwk.values()) / len(qwk)\n    if avg_qwk - best_qwk > 1e-6:\n        best_qwk = avg_qwk\n        print(f\"New best QWK: {best_qwk:.4f}\")\n        torch.save(model.state_dict(), \"/kaggle/working/best_first_model.pth\")\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T19:42:05.410610Z","iopub.execute_input":"2025-05-17T19:42:05.410900Z","iopub.status.idle":"2025-05-17T20:00:45.609524Z","shell.execute_reply.started":"2025-05-17T19:42:05.410879Z","shell.execute_reply":"2025-05-17T20:00:45.608489Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 501/501 [04:02<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 0.6874591003278059\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 163/163 [00:32<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7238\nQWK for Cohesion: 0.6081\nQWK for Syntax: 0.6857\nQWK for Vocabulary: 0.6304\nQWK for Phraseology: 0.6726\nQWK for Grammar: 0.6995\nQWK for Conventions: 0.6656\nNew best QWK: 0.6694\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 501/501 [04:01<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 0.6690997454577577\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 163/163 [00:32<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7406\nQWK for Cohesion: 0.5865\nQWK for Syntax: 0.6775\nQWK for Vocabulary: 0.6098\nQWK for Phraseology: 0.6473\nQWK for Grammar: 0.7143\nQWK for Conventions: 0.6805\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 501/501 [04:02<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 0.6634130186425473\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 163/163 [00:32<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7644\nQWK for Cohesion: 0.6296\nQWK for Syntax: 0.7023\nQWK for Vocabulary: 0.6808\nQWK for Phraseology: 0.7045\nQWK for Grammar: 0.7500\nQWK for Conventions: 0.6948\nNew best QWK: 0.7038\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 501/501 [04:01<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 0.6576157647692514\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 163/163 [00:32<00:00,  5.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7485\nQWK for Cohesion: 0.6230\nQWK for Syntax: 0.7065\nQWK for Vocabulary: 0.6619\nQWK for Phraseology: 0.6846\nQWK for Grammar: 0.7309\nQWK for Conventions: 0.6971\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:   7%|▋         | 37/501 [00:17<03:44,  2.07it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_125/2404413210.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreg_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"model = DebertaNHeads()\nmodel.load_state_dict(torch.load('/kaggle/working/best_first_model.pth', weights_only=False))\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:00:49.684344Z","iopub.execute_input":"2025-05-17T20:00:49.685020Z","iopub.status.idle":"2025-05-17T20:00:53.073144Z","shell.execute_reply.started":"2025-05-17T20:00:49.684995Z","shell.execute_reply":"2025-05-17T20:00:53.072432Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DebertaNHeads(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128002, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (regression_heads): ModuleList(\n    (0-6): 7 x Linear(in_features=768, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model.eval()\nloop = tqdm(test_loader)\n\nall_preds = []\nall_targets = []\n\nwith torch.no_grad():\n    for batch in loop:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        target = batch[\"scores\"].to(device)\n        preds = model(input_ids, attention_mask)\n        all_preds.append(preds)\n        all_targets.append(target)\nall_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\nall_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\nqwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:00:57.498359Z","iopub.execute_input":"2025-05-17T20:00:57.498930Z","iopub.status.idle":"2025-05-17T20:01:30.003873Z","shell.execute_reply.started":"2025-05-17T20:00:57.498908Z","shell.execute_reply":"2025-05-17T20:01:30.003082Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 163/163 [00:32<00:00,  5.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7529\nQWK for Cohesion: 0.6213\nQWK for Syntax: 0.6706\nQWK for Vocabulary: 0.6427\nQWK for Phraseology: 0.6564\nQWK for Grammar: 0.7098\nQWK for Conventions: 0.6655\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"df_add_cont = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_content.tsv',\n                          sep='\\t', header=0, index_col=0)\ndf_add_lang = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_language.tsv',\n                          sep='\\t', header=0, index_col=0)\ndf_add_org = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_organization.tsv',\n                          sep='\\t', header=0, index_col=0)\ndf_add_new = pd.read_csv('/kaggle/input/dress-d/DREsS_New.tsv',\n                          sep='\\t', header=0, index_col=0)\ndf_add_std = pd.read_csv('/kaggle/input/dress-d/DREsS_Std.tsv',\n                          sep='\\t', header=0, index_col=0)\ndf_add = pd.concat([df_add_cont,\n                    df_add_lang,\n                    df_add_org,\n                    df_add_new,\n                    df_add_std], ignore_index=True) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:01:39.041135Z","iopub.execute_input":"2025-05-17T20:01:39.041436Z","iopub.status.idle":"2025-05-17T20:01:41.240559Z","shell.execute_reply.started":"2025-05-17T20:01:39.041413Z","shell.execute_reply":"2025-05-17T20:01:41.239986Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"df_add","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:01:49.285876Z","iopub.execute_input":"2025-05-17T20:01:49.286506Z","iopub.status.idle":"2025-05-17T20:01:49.309230Z","shell.execute_reply.started":"2025-05-17T20:01:49.286460Z","shell.execute_reply":"2025-05-17T20:01:49.308531Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                  prompt  \\\n0      Write about patience. Being patient means that...   \n1      Smoking should be completely banned at all the...   \n2      Write about patience. Being patient means that...   \n3      We all understand the benefits of laughter. Fo...   \n4      Write about patience. Being patient means that...   \n...                                                  ...   \n48967  It is important for college students to have a...   \n48968  Smoking should be completely banned at all the...   \n48969  It is important for college students to have a...   \n48970  It is important for college students to have a...   \n48971  Smoking should be completely banned at all the...   \n\n                                                   essay   content  language  \\\n0      @CAPS1 I'm here to prove you wrong and tell yo...  1.000000       NaN   \n1      So how can someone say 'No, you @MONTH1 not li...  1.000000       NaN   \n2      In @CAPS1 middle school, in @PERSON2's dirty a...  1.000000       NaN   \n3      One of the most oddest things in life is how p...  1.000000       NaN   \n4      A time when I was patient was when I was helpi...  1.000000       NaN   \n...                                                  ...       ...       ...   \n48967  I think that it is important for college stude...  4.166667  3.958333   \n48968  I agree with the statement that smoking should...  3.750000  3.208333   \n48969  In my opinion, I am strongly agree with the id...  3.333333  3.333333   \n48970  A part time job means to work in separate time...  1.666667  1.875000   \n48971  Despite the fact that the media tells us that ...  2.500000  3.750000   \n\n       organization      total     source  \n0               NaN        NaN        NaN  \n1               NaN        NaN        NaN  \n2               NaN        NaN        NaN  \n3               NaN        NaN        NaN  \n4               NaN        NaN        NaN  \n...             ...        ...        ...  \n48967      4.583333  12.708333  ICNALE EE  \n48968      3.750000  10.708333  ICNALE EE  \n48969      2.916667   9.583333  ICNALE EE  \n48970      1.666667   5.208333  ICNALE EE  \n48971      2.916667   9.166667  ICNALE EE  \n\n[48972 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>essay</th>\n      <th>content</th>\n      <th>language</th>\n      <th>organization</th>\n      <th>total</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Write about patience. Being patient means that...</td>\n      <td>@CAPS1 I'm here to prove you wrong and tell yo...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Smoking should be completely banned at all the...</td>\n      <td>So how can someone say 'No, you @MONTH1 not li...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Write about patience. Being patient means that...</td>\n      <td>In @CAPS1 middle school, in @PERSON2's dirty a...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all understand the benefits of laughter. Fo...</td>\n      <td>One of the most oddest things in life is how p...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write about patience. Being patient means that...</td>\n      <td>A time when I was patient was when I was helpi...</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48967</th>\n      <td>It is important for college students to have a...</td>\n      <td>I think that it is important for college stude...</td>\n      <td>4.166667</td>\n      <td>3.958333</td>\n      <td>4.583333</td>\n      <td>12.708333</td>\n      <td>ICNALE EE</td>\n    </tr>\n    <tr>\n      <th>48968</th>\n      <td>Smoking should be completely banned at all the...</td>\n      <td>I agree with the statement that smoking should...</td>\n      <td>3.750000</td>\n      <td>3.208333</td>\n      <td>3.750000</td>\n      <td>10.708333</td>\n      <td>ICNALE EE</td>\n    </tr>\n    <tr>\n      <th>48969</th>\n      <td>It is important for college students to have a...</td>\n      <td>In my opinion, I am strongly agree with the id...</td>\n      <td>3.333333</td>\n      <td>3.333333</td>\n      <td>2.916667</td>\n      <td>9.583333</td>\n      <td>ICNALE EE</td>\n    </tr>\n    <tr>\n      <th>48970</th>\n      <td>It is important for college students to have a...</td>\n      <td>A part time job means to work in separate time...</td>\n      <td>1.666667</td>\n      <td>1.875000</td>\n      <td>1.666667</td>\n      <td>5.208333</td>\n      <td>ICNALE EE</td>\n    </tr>\n    <tr>\n      <th>48971</th>\n      <td>Smoking should be completely banned at all the...</td>\n      <td>Despite the fact that the media tells us that ...</td>\n      <td>2.500000</td>\n      <td>3.750000</td>\n      <td>2.916667</td>\n      <td>9.166667</td>\n      <td>ICNALE EE</td>\n    </tr>\n  </tbody>\n</table>\n<p>48972 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"cols_to_norm = ['content', 'language', 'organization', 'total', 'source']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:04:38.213809Z","iopub.execute_input":"2025-05-17T20:04:38.214530Z","iopub.status.idle":"2025-05-17T20:04:38.218010Z","shell.execute_reply.started":"2025-05-17T20:04:38.214506Z","shell.execute_reply":"2025-05-17T20:04:38.217156Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def normalize_numeric_only(df):\n    numeric_cols = df.select_dtypes(include='number').columns\n    non_numeric_cols = df.columns.difference(numeric_cols)\n    \n    scaler = MinMaxScaler()\n    df_numeric = df[numeric_cols]\n    df_filled = df_numeric.fillna(0)\n    df_scaled = pd.DataFrame(scaler.fit_transform(df_filled), columns=numeric_cols, index=df.index)\n\n    df_scaled = df_numeric.where(df_numeric.isna(), df_scaled)\n\n    return pd.concat([df_scaled, df[non_numeric_cols]], axis=1)[df.columns]\n\ndf_add_norm = normalize_numeric_only(df_add)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:06:18.373142Z","iopub.execute_input":"2025-05-17T20:06:18.373437Z","iopub.status.idle":"2025-05-17T20:06:18.404835Z","shell.execute_reply.started":"2025-05-17T20:06:18.373416Z","shell.execute_reply":"2025-05-17T20:06:18.404260Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df_add_norm = df_add_norm.drop(['prompt', 'source'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:07:27.150468Z","iopub.execute_input":"2025-05-17T20:07:27.151164Z","iopub.status.idle":"2025-05-17T20:07:27.157943Z","shell.execute_reply.started":"2025-05-17T20:07:27.151134Z","shell.execute_reply":"2025-05-17T20:07:27.157214Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_add_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:07:33.121440Z","iopub.execute_input":"2025-05-17T20:07:33.121739Z","iopub.status.idle":"2025-05-17T20:07:33.132980Z","shell.execute_reply.started":"2025-05-17T20:07:33.121718Z","shell.execute_reply":"2025-05-17T20:07:33.132179Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                   essay   content  language  \\\n0      @CAPS1 I'm here to prove you wrong and tell yo...  0.200000       NaN   \n1      So how can someone say 'No, you @MONTH1 not li...  0.200000       NaN   \n2      In @CAPS1 middle school, in @PERSON2's dirty a...  0.200000       NaN   \n3      One of the most oddest things in life is how p...  0.200000       NaN   \n4      A time when I was patient was when I was helpi...  0.200000       NaN   \n...                                                  ...       ...       ...   \n48967  I think that it is important for college stude...  0.833333  0.791667   \n48968  I agree with the statement that smoking should...  0.750000  0.641667   \n48969  In my opinion, I am strongly agree with the id...  0.666667  0.666667   \n48970  A part time job means to work in separate time...  0.333333  0.375000   \n48971  Despite the fact that the media tells us that ...  0.500000  0.750000   \n\n       organization     total  \n0               NaN       NaN  \n1               NaN       NaN  \n2               NaN       NaN  \n3               NaN       NaN  \n4               NaN       NaN  \n...             ...       ...  \n48967      0.916667  0.847222  \n48968      0.750000  0.713889  \n48969      0.583333  0.638889  \n48970      0.333333  0.347222  \n48971      0.583333  0.611111  \n\n[48972 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n      <th>content</th>\n      <th>language</th>\n      <th>organization</th>\n      <th>total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@CAPS1 I'm here to prove you wrong and tell yo...</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>So how can someone say 'No, you @MONTH1 not li...</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In @CAPS1 middle school, in @PERSON2's dirty a...</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>One of the most oddest things in life is how p...</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A time when I was patient was when I was helpi...</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48967</th>\n      <td>I think that it is important for college stude...</td>\n      <td>0.833333</td>\n      <td>0.791667</td>\n      <td>0.916667</td>\n      <td>0.847222</td>\n    </tr>\n    <tr>\n      <th>48968</th>\n      <td>I agree with the statement that smoking should...</td>\n      <td>0.750000</td>\n      <td>0.641667</td>\n      <td>0.750000</td>\n      <td>0.713889</td>\n    </tr>\n    <tr>\n      <th>48969</th>\n      <td>In my opinion, I am strongly agree with the id...</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.583333</td>\n      <td>0.638889</td>\n    </tr>\n    <tr>\n      <th>48970</th>\n      <td>A part time job means to work in separate time...</td>\n      <td>0.333333</td>\n      <td>0.375000</td>\n      <td>0.333333</td>\n      <td>0.347222</td>\n    </tr>\n    <tr>\n      <th>48971</th>\n      <td>Despite the fact that the media tells us that ...</td>\n      <td>0.500000</td>\n      <td>0.750000</td>\n      <td>0.583333</td>\n      <td>0.611111</td>\n    </tr>\n  </tbody>\n</table>\n<p>48972 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"texts = df_add_norm['essay']\ntexts = texts.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:08:37.431439Z","iopub.execute_input":"2025-05-17T20:08:37.431974Z","iopub.status.idle":"2025-05-17T20:08:37.443131Z","shell.execute_reply.started":"2025-05-17T20:08:37.431954Z","shell.execute_reply":"2025-05-17T20:08:37.442554Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"pseudo = pd.concat([train_df['full_text'], texts], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:08:44.745713Z","iopub.execute_input":"2025-05-17T20:08:44.746451Z","iopub.status.idle":"2025-05-17T20:08:44.751932Z","shell.execute_reply.started":"2025-05-17T20:08:44.746424Z","shell.execute_reply":"2025-05-17T20:08:44.751356Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class UnlabeledDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.df = dataframe\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        text = row.tolist()\n\n\n        inputs = self.tokenizer(text,\n                                padding=\"max_length\",\n                                truncation=True,\n                                return_tensors=\"pt\",\n                                max_length=512)\n\n        return {\n            \"input_ids\": inputs[\"input_ids\"],\n            \"attention_mask\": inputs[\"attention_mask\"]\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:08:46.472892Z","iopub.execute_input":"2025-05-17T20:08:46.473532Z","iopub.status.idle":"2025-05-17T20:08:46.478295Z","shell.execute_reply.started":"2025-05-17T20:08:46.473504Z","shell.execute_reply":"2025-05-17T20:08:46.477493Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"add_dataset = UnlabeledDataset(pseudo, tokenizer)\nadd_loader = DataLoader(add_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:08:47.948024Z","iopub.execute_input":"2025-05-17T20:08:47.948315Z","iopub.status.idle":"2025-05-17T20:08:47.952430Z","shell.execute_reply.started":"2025-05-17T20:08:47.948293Z","shell.execute_reply":"2025-05-17T20:08:47.951469Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"model.eval()\nloop = tqdm(add_loader)\nall_preds = []\nwith torch.no_grad():\n    for batch in loop:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        preds = model(input_ids, attention_mask)\n        all_preds.append(preds)\nall_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:08:49.923407Z","iopub.execute_input":"2025-05-17T20:08:49.924152Z","iopub.status.idle":"2025-05-17T20:30:47.606966Z","shell.execute_reply.started":"2025-05-17T20:08:49.924119Z","shell.execute_reply":"2025-05-17T20:30:47.606064Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6585/6585 [21:57<00:00,  5.00it/s]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"columns=[\"Overall\",\n         \"Cohesion\",\n         \"Syntax\",\n         \"Vocabulary\",\n         \"Phraseology\",\n         \"Grammar\",\n         \"Conventions\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:31:05.204148Z","iopub.execute_input":"2025-05-17T20:31:05.204430Z","iopub.status.idle":"2025-05-17T20:31:05.208328Z","shell.execute_reply.started":"2025-05-17T20:31:05.204404Z","shell.execute_reply":"2025-05-17T20:31:05.207520Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"pseudo_df = pd.DataFrame(data=list(zip(*all_preds.T)), columns=columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:41:04.293653Z","iopub.execute_input":"2025-05-17T20:41:04.293944Z","iopub.status.idle":"2025-05-17T20:41:04.405516Z","shell.execute_reply.started":"2025-05-17T20:41:04.293923Z","shell.execute_reply":"2025-05-17T20:41:04.404820Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"pseudo_df['full_text'] = pseudo.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:41:04.840005Z","iopub.execute_input":"2025-05-17T20:41:04.840617Z","iopub.status.idle":"2025-05-17T20:41:04.846395Z","shell.execute_reply.started":"2025-05-17T20:41:04.840589Z","shell.execute_reply":"2025-05-17T20:41:04.845492Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"for col in columns:\n    for i in range(len(train_df)):\n        pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:41:07.571132Z","iopub.execute_input":"2025-05-17T20:41:07.571891Z","iopub.status.idle":"2025-05-17T20:41:25.078346Z","shell.execute_reply.started":"2025-05-17T20:41:07.571850Z","shell.execute_reply":"2025-05-17T20:41:25.077588Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6211936175823212' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8517360389232635' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5328886806964874' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7305084764957428' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6291497051715851' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5573436319828033' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n/tmp/ipykernel_125/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9066612422466278' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"copy_map = {\n    \"language\": [\"Syntax\", \"Vocabulary\", \"Phraseology\", \"Grammar\", \"Conventions\"],\n    \"organization\" : [\"Cohesion\"],\n    \"total\" : [\"Overall\"]\n}\n\nfor original_col, new_names in copy_map.items():\n    for new_col in new_names:\n        df_add_norm[new_col] = df_add_norm[original_col]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:31:55.353021Z","iopub.execute_input":"2025-05-17T20:31:55.353528Z","iopub.status.idle":"2025-05-17T20:31:55.360633Z","shell.execute_reply.started":"2025-05-17T20:31:55.353502Z","shell.execute_reply":"2025-05-17T20:31:55.360044Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"df_add_marks = df_add_norm.dropna(subset=[\"essay\"])[columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:34:10.294721Z","iopub.execute_input":"2025-05-17T20:34:10.295508Z","iopub.status.idle":"2025-05-17T20:34:10.319661Z","shell.execute_reply.started":"2025-05-17T20:34:10.295460Z","shell.execute_reply":"2025-05-17T20:34:10.318893Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"df_add_marks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:34:16.307403Z","iopub.execute_input":"2025-05-17T20:34:16.307708Z","iopub.status.idle":"2025-05-17T20:34:16.320895Z","shell.execute_reply.started":"2025-05-17T20:34:16.307685Z","shell.execute_reply":"2025-05-17T20:34:16.320002Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"        Overall  Cohesion    Syntax  Vocabulary  Phraseology   Grammar  \\\n0           NaN       NaN       NaN         NaN          NaN       NaN   \n1           NaN       NaN       NaN         NaN          NaN       NaN   \n2           NaN       NaN       NaN         NaN          NaN       NaN   \n3           NaN       NaN       NaN         NaN          NaN       NaN   \n4           NaN       NaN       NaN         NaN          NaN       NaN   \n...         ...       ...       ...         ...          ...       ...   \n48967  0.847222  0.916667  0.791667    0.791667     0.791667  0.791667   \n48968  0.713889  0.750000  0.641667    0.641667     0.641667  0.641667   \n48969  0.638889  0.583333  0.666667    0.666667     0.666667  0.666667   \n48970  0.347222  0.333333  0.375000    0.375000     0.375000  0.375000   \n48971  0.611111  0.583333  0.750000    0.750000     0.750000  0.750000   \n\n       Conventions  \n0              NaN  \n1              NaN  \n2              NaN  \n3              NaN  \n4              NaN  \n...            ...  \n48967     0.791667  \n48968     0.641667  \n48969     0.666667  \n48970     0.375000  \n48971     0.750000  \n\n[48672 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Overall</th>\n      <th>Cohesion</th>\n      <th>Syntax</th>\n      <th>Vocabulary</th>\n      <th>Phraseology</th>\n      <th>Grammar</th>\n      <th>Conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48967</th>\n      <td>0.847222</td>\n      <td>0.916667</td>\n      <td>0.791667</td>\n      <td>0.791667</td>\n      <td>0.791667</td>\n      <td>0.791667</td>\n      <td>0.791667</td>\n    </tr>\n    <tr>\n      <th>48968</th>\n      <td>0.713889</td>\n      <td>0.750000</td>\n      <td>0.641667</td>\n      <td>0.641667</td>\n      <td>0.641667</td>\n      <td>0.641667</td>\n      <td>0.641667</td>\n    </tr>\n    <tr>\n      <th>48969</th>\n      <td>0.638889</td>\n      <td>0.583333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>48970</th>\n      <td>0.347222</td>\n      <td>0.333333</td>\n      <td>0.375000</td>\n      <td>0.375000</td>\n      <td>0.375000</td>\n      <td>0.375000</td>\n      <td>0.375000</td>\n    </tr>\n    <tr>\n      <th>48971</th>\n      <td>0.611111</td>\n      <td>0.583333</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n    </tr>\n  </tbody>\n</table>\n<p>48672 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"len(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:39:50.301717Z","iopub.execute_input":"2025-05-17T20:39:50.301990Z","iopub.status.idle":"2025-05-17T20:39:50.306735Z","shell.execute_reply.started":"2025-05-17T20:39:50.301969Z","shell.execute_reply":"2025-05-17T20:39:50.306179Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"4005"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"len(pseudo_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:39:57.183404Z","iopub.execute_input":"2025-05-17T20:39:57.184138Z","iopub.status.idle":"2025-05-17T20:39:57.188921Z","shell.execute_reply.started":"2025-05-17T20:39:57.184102Z","shell.execute_reply":"2025-05-17T20:39:57.188200Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"52677"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"len(df_add_marks.reset_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:40:10.219298Z","iopub.execute_input":"2025-05-17T20:40:10.219607Z","iopub.status.idle":"2025-05-17T20:40:10.227159Z","shell.execute_reply.started":"2025-05-17T20:40:10.219585Z","shell.execute_reply":"2025-05-17T20:40:10.226351Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"48672"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"for col in columns:\n    for i in range(len(train_df), len(pseudo_df)):\n        if pd.notna(df_add_marks.reset_index().loc[i - len(train_df), col]):\n            pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + df_add_marks.reset_index().loc[i - len(train_df), col]) / 2\n        else:\n            pseudo_df.loc[i, col] = pseudo_df.loc[i, col]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:41:34.755490Z","iopub.execute_input":"2025-05-17T20:41:34.755766Z","iopub.status.idle":"2025-05-17T20:51:46.780146Z","shell.execute_reply.started":"2025-05-17T20:41:34.755745Z","shell.execute_reply":"2025-05-17T20:51:46.779529Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"class PseudoDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.df = dataframe\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        text = row[\"full_text\"].to_list()\n\n\n        inputs = self.tokenizer(text,\n                                padding=\"max_length\",\n                                truncation=True,\n                                return_tensors=\"pt\",\n                                max_length=512)\n\n        scores = torch.tensor(row[columns].values, dtype=torch.float32)\n\n        return {\n            \"input_ids\": inputs[\"input_ids\"],\n            \"attention_mask\": inputs[\"attention_mask\"],\n            \"scores\": scores\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:46.781437Z","iopub.execute_input":"2025-05-17T20:51:46.782098Z","iopub.status.idle":"2025-05-17T20:51:46.787244Z","shell.execute_reply.started":"2025-05-17T20:51:46.782071Z","shell.execute_reply":"2025-05-17T20:51:46.786651Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"combined_dataset = PseudoDataset(pseudo_df, tokenizer)\ncombined_loader = DataLoader(combined_dataset, batch_size=8, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:52.477944Z","iopub.execute_input":"2025-05-17T20:51:52.478215Z","iopub.status.idle":"2025-05-17T20:51:52.482121Z","shell.execute_reply.started":"2025-05-17T20:51:52.478195Z","shell.execute_reply":"2025-05-17T20:51:52.481303Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"model_2 = DebertaNHeads()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:53.025633Z","iopub.execute_input":"2025-05-17T20:51:53.026194Z","iopub.status.idle":"2025-05-17T20:51:55.285243Z","shell.execute_reply.started":"2025-05-17T20:51:53.026163Z","shell.execute_reply":"2025-05-17T20:51:55.284682Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"for layer in model_2.deberta.encoder.layer[:7]:\n    for param in layer.parameters():\n        param.requires_grad = False\nfor param in model_2.deberta.embeddings.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:55.286345Z","iopub.execute_input":"2025-05-17T20:51:55.286586Z","iopub.status.idle":"2025-05-17T20:51:55.291638Z","shell.execute_reply.started":"2025-05-17T20:51:55.286568Z","shell.execute_reply":"2025-05-17T20:51:55.290824Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"num_training_steps = len(combined_loader) * 10\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_2.to(device)\noptimizer = optim.AdamW(model_2.parameters(), lr=4e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=num_training_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:56.438798Z","iopub.execute_input":"2025-05-17T20:51:56.439511Z","iopub.status.idle":"2025-05-17T20:51:56.649585Z","shell.execute_reply.started":"2025-05-17T20:51:56.439469Z","shell.execute_reply":"2025-05-17T20:51:56.648697Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"train_losses = []\nqwk_scores = []\nbest_qwk = -float('inf')\n\nmodel_2.train()\nfor epoch in range(10):\n    loss_per_epoch = 0\n    loop = tqdm(combined_loader, desc=f\"Epoch {epoch+1}\")\n\n    all_preds = []\n    all_targets = []\n\n    for batch in loop:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        reg_target = batch[\"scores\"].to(device)\n        reg_preds = model_2(input_ids, attention_mask)\n        loss = 0\n        for i in range(7):\n            loss += combined_loss(reg_preds[:, i], reg_target[:, i])\n        loss /= 7\n        loss_per_epoch += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model_2.parameters(), max_norm=10)\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = loss_per_epoch / len(train_loader)\n    train_losses.append(avg_loss)\n    print(f'Loss_per_epoch = {avg_loss}')\n\n    model_2.eval()\n    loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}\")\n    with torch.no_grad():\n        for batch in loop:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            reg_target = batch[\"scores\"].to(device)\n            reg_preds = model_2(input_ids, attention_mask)\n            all_preds.append(reg_preds)\n            all_targets.append(reg_target)\n    all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n    all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n    qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])\n    qwk_scores.append(qwk)\n    avg_qwk = sum(qwk.values()) / len(qwk)\n    if avg_qwk - best_qwk > 1e-6:\n        best_qwk = avg_qwk\n        print(f\"New best QWK: {best_qwk:.4f}\")\n        torch.save(model_2.state_dict(), \"/kaggle/working/best_second_model.pth\")\n    model_2.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T20:51:58.531496Z","iopub.execute_input":"2025-05-17T20:51:58.532090Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 6585/6585 [55:28<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 8.293102087434418\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 163/163 [00:32<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7573\nQWK for Cohesion: 0.6301\nQWK for Syntax: 0.6911\nQWK for Vocabulary: 0.6823\nQWK for Phraseology: 0.6906\nQWK for Grammar: 0.7395\nQWK for Conventions: 0.6827\nNew best QWK: 0.6962\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 6585/6585 [55:26<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 8.165109681690524\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 163/163 [00:32<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7489\nQWK for Cohesion: 0.5859\nQWK for Syntax: 0.6828\nQWK for Vocabulary: 0.6705\nQWK for Phraseology: 0.6947\nQWK for Grammar: 0.7439\nQWK for Conventions: 0.6861\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 6585/6585 [55:26<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 8.149318526842874\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 163/163 [00:32<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7602\nQWK for Cohesion: 0.6335\nQWK for Syntax: 0.6920\nQWK for Vocabulary: 0.6781\nQWK for Phraseology: 0.7058\nQWK for Grammar: 0.7431\nQWK for Conventions: 0.6944\nNew best QWK: 0.7010\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 6585/6585 [55:26<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss_per_epoch = 8.138318433435614\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 163/163 [00:32<00:00,  4.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7539\nQWK for Cohesion: 0.6285\nQWK for Syntax: 0.6889\nQWK for Vocabulary: 0.6635\nQWK for Phraseology: 0.6867\nQWK for Grammar: 0.7369\nQWK for Conventions: 0.6996\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  37%|███▋      | 2453/6585 [20:39<34:46,  1.98it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model_2 = DebertaNHeads()\nmodel_2.load_state_dict(torch.load('/kaggle/working/best_second_model.pth', weights_only=True))\nmodel_2.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:09:08.279822Z","iopub.execute_input":"2025-05-18T07:09:08.280398Z","iopub.status.idle":"2025-05-18T07:09:11.814265Z","shell.execute_reply.started":"2025-05-18T07:09:08.280367Z","shell.execute_reply":"2025-05-18T07:09:11.813587Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"DebertaNHeads(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128002, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (regression_heads): ModuleList(\n    (0-6): 7 x Linear(in_features=768, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"model_2.eval()\nloop = tqdm(test_loader)\n\nall_preds = []\nall_targets = []\n\nwith torch.no_grad():\n    for batch in loop:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        target = batch[\"scores\"].to(device)\n        preds = model_2(input_ids, attention_mask)\n        all_preds.append(preds)\n        all_targets.append(target)\nall_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\nall_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\nqwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T07:09:14.429243Z","iopub.execute_input":"2025-05-18T07:09:14.429571Z","iopub.status.idle":"2025-05-18T07:09:46.955641Z","shell.execute_reply.started":"2025-05-18T07:09:14.429547Z","shell.execute_reply":"2025-05-18T07:09:46.954598Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 163/163 [00:32<00:00,  5.02it/s]","output_type":"stream"},{"name":"stdout","text":"QWK for Overall: 0.7450\nQWK for Cohesion: 0.6296\nQWK for Syntax: 0.6693\nQWK for Vocabulary: 0.6498\nQWK for Phraseology: 0.6685\nQWK for Grammar: 0.7091\nQWK for Conventions: 0.6848\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}