{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:47.014177Z",
     "iopub.status.busy": "2025-05-16T23:22:47.013939Z",
     "iopub.status.idle": "2025-05-16T23:22:50.308071Z",
     "shell.execute_reply": "2025-05-16T23:22:50.307359Z",
     "shell.execute_reply.started": "2025-05-16T23:22:47.014152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:50.312272Z",
     "iopub.status.busy": "2025-05-16T23:22:50.312051Z",
     "iopub.status.idle": "2025-05-16T23:22:55.502693Z",
     "shell.execute_reply": "2025-05-16T23:22:55.501930Z",
     "shell.execute_reply.started": "2025-05-16T23:22:50.312247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:55.503917Z",
     "iopub.status.busy": "2025-05-16T23:22:55.503482Z",
     "iopub.status.idle": "2025-05-16T23:22:55.691607Z",
     "shell.execute_reply": "2025-05-16T23:22:55.690998Z",
     "shell.execute_reply.started": "2025-05-16T23:22:55.503898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/dress-d/train.csv', index_col=0)\n",
    "val_df = pd.read_csv('/kaggle/input/dress-d/val.csv', index_col=0)\n",
    "test_df = pd.read_csv('/kaggle/input/dress-d/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:55.692598Z",
     "iopub.status.busy": "2025-05-16T23:22:55.692385Z",
     "iopub.status.idle": "2025-05-16T23:22:55.698561Z",
     "shell.execute_reply": "2025-05-16T23:22:55.697914Z",
     "shell.execute_reply.started": "2025-05-16T23:22:55.692581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EllipseDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row[\"full_text\"].to_list()\n",
    "\n",
    "\n",
    "\n",
    "        scores = torch.tensor(row[[\"Overall\",\n",
    "                                   \"Cohesion\",\n",
    "                                   \"Syntax\",\n",
    "                                   \"Vocabulary\",\n",
    "                                   \"Phraseology\",\n",
    "                                   \"Grammar\",\n",
    "                                   \"Conventions\"]\n",
    "                                  ].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        inputs = self.tokenizer(text,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=512)\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "            \"scores\": scores\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:55.700310Z",
     "iopub.status.busy": "2025-05-16T23:22:55.700052Z",
     "iopub.status.idle": "2025-05-16T23:22:56.300722Z",
     "shell.execute_reply": "2025-05-16T23:22:56.300114Z",
     "shell.execute_reply.started": "2025-05-16T23:22:55.700294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\", use_fast=False)\n",
    "special_token = \"\\n\\n\"\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [special_token]})\n",
    "\n",
    "train_dataset = EllipseDataset(train_df.reset_index(drop=True), tokenizer)\n",
    "val_dataset = EllipseDataset(val_df.reset_index(drop=True), tokenizer)\n",
    "test_dataset = EllipseDataset(test_df.reset_index(drop=True), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:56.301685Z",
     "iopub.status.busy": "2025-05-16T23:22:56.301464Z",
     "iopub.status.idle": "2025-05-16T23:22:56.310891Z",
     "shell.execute_reply": "2025-05-16T23:22:56.310183Z",
     "shell.execute_reply.started": "2025-05-16T23:22:56.301668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DebertaNHeads(nn.Module):\n",
    "    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_aspects=7):\n",
    "        super().__init__()\n",
    "        self.deberta = AutoModel.from_pretrained(model_name)\n",
    "        self.deberta.resize_token_embeddings(len(tokenizer))\n",
    "        hidden_size = self.deberta.config.hidden_size\n",
    "\n",
    "        self.num_aspects = num_aspects\n",
    "        \n",
    "        self.regression_heads = nn.ModuleList([\n",
    "            nn.Linear(hidden_size, 1) for _ in range(num_aspects)\n",
    "        ])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for head in self.regression_heads:\n",
    "            init.xavier_uniform_(head.weight)\n",
    "            if head.bias is not None:\n",
    "                init.zeros_(head.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        regression_outputs = []\n",
    "\n",
    "        for i in range(self.num_aspects):\n",
    "            regression_outputs.append(self.sigmoid(self.regression_heads[i](pooled_output)))\n",
    "\n",
    "        regression_outputs = torch.cat(regression_outputs, dim=1)\n",
    "\n",
    "        return regression_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:06.778957Z",
     "iopub.status.busy": "2025-05-16T23:23:06.778669Z",
     "iopub.status.idle": "2025-05-16T23:23:12.792522Z",
     "shell.execute_reply": "2025-05-16T23:23:12.791921Z",
     "shell.execute_reply.started": "2025-05-16T23:23:06.778936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 23:23:08.427780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747437788.451324     145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747437788.458343     145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "model = DebertaNHeads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:22:59.805921Z",
     "iopub.status.busy": "2025-05-16T23:22:59.805642Z",
     "iopub.status.idle": "2025-05-16T23:22:59.815891Z",
     "shell.execute_reply": "2025-05-16T23:22:59.815113Z",
     "shell.execute_reply.started": "2025-05-16T23:22:59.805899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:15.761896Z",
     "iopub.status.busy": "2025-05-16T23:23:15.761283Z",
     "iopub.status.idle": "2025-05-16T23:23:16.074214Z",
     "shell.execute_reply": "2025-05-16T23:23:16.073641Z",
     "shell.execute_reply.started": "2025-05-16T23:23:15.761872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "num_training_steps = len(train_loader) * 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=4e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:26.956735Z",
     "iopub.status.busy": "2025-05-16T23:23:26.955966Z",
     "iopub.status.idle": "2025-05-16T23:23:26.960405Z",
     "shell.execute_reply": "2025-05-16T23:23:26.959609Z",
     "shell.execute_reply.started": "2025-05-16T23:23:26.956705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def combined_loss(reg_preds, reg_labels):\n",
    "    regression_loss = nn.BCELoss()\n",
    "    total_reg_loss = 0\n",
    "    total_reg_loss += regression_loss(reg_preds, reg_labels)\n",
    "\n",
    "    return total_reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:27.211125Z",
     "iopub.status.busy": "2025-05-16T23:23:27.210534Z",
     "iopub.status.idle": "2025-05-16T23:23:27.216177Z",
     "shell.execute_reply": "2025-05-16T23:23:27.215486Z",
     "shell.execute_reply.started": "2025-05-16T23:23:27.211073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_qwk_for_aspects(class_preds, class_labels, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions']):\n",
    "    class_preds = class_preds * 4 + 1\n",
    "    class_labels = class_labels * 4 + 1\n",
    "\n",
    "    class_preds = np.round(class_preds * 2) / 2\n",
    "    class_labels = np.round(class_labels * 2) / 2\n",
    "\n",
    "    class_preds = ((class_preds - 1) * 2).astype(int)\n",
    "    class_labels = ((class_labels - 1) * 2).astype(int)\n",
    "\n",
    "    qwk_scores = {}\n",
    "    for i, aspect in enumerate(aspects):\n",
    "        qwk_score = cohen_kappa_score(class_preds[:, i], class_labels[:, i], weights='quadratic')\n",
    "        qwk_scores[aspect] = qwk_score\n",
    "        print(f'QWK for {aspect}: {qwk_score:.4f}')\n",
    "\n",
    "    return qwk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:29.860020Z",
     "iopub.status.busy": "2025-05-16T23:23:29.859278Z",
     "iopub.status.idle": "2025-05-16T23:23:29.864535Z",
     "shell.execute_reply": "2025-05-16T23:23:29.863709Z",
     "shell.execute_reply.started": "2025-05-16T23:23:29.859994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in model.deberta.encoder.layer[:9]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "for param in model.deberta.embeddings.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "qwk_scores = []\n",
    "best_qwk = -float('inf')\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    loss_per_epoch = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        reg_target = batch[\"scores\"].to(device)\n",
    "        reg_preds = model(input_ids, attention_mask)\n",
    "        loss = 0\n",
    "        for i in range(7):\n",
    "            loss += combined_loss(reg_preds[:, i], reg_target[:, i])\n",
    "        loss /= 7\n",
    "        loss_per_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = loss_per_epoch / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Loss_per_epoch = {avg_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            reg_target = batch[\"scores\"].to(device)\n",
    "            reg_preds = model(input_ids, attention_mask)\n",
    "            all_preds.append(reg_preds)\n",
    "            all_targets.append(reg_target)\n",
    "    all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "    qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])\n",
    "    qwk_scores.append(qwk)\n",
    "    avg_qwk = sum(qwk.values()) / len(qwk)\n",
    "    if avg_qwk - best_qwk > 1e-6:\n",
    "        best_qwk = avg_qwk\n",
    "        print(f\"New best QWK: {best_qwk:.4f}\")\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_first_model.pth\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:23:36.287926Z",
     "iopub.status.busy": "2025-05-16T23:23:36.287214Z",
     "iopub.status.idle": "2025-05-16T23:23:39.151535Z",
     "shell.execute_reply": "2025-05-16T23:23:39.150877Z",
     "shell.execute_reply.started": "2025-05-16T23:23:36.287902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaNHeads(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128002, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (regression_heads): ModuleList(\n",
       "    (0-6): 7 x Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DebertaNHeads()\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_first_model.pth', weights_only=False))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loop = tqdm(test_loader)\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        target = batch[\"scores\"].to(device)\n",
    "        preds = model(input_ids, attention_mask)\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(target)\n",
    "all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:28:01.921280Z",
     "iopub.status.busy": "2025-05-16T23:28:01.920844Z",
     "iopub.status.idle": "2025-05-16T23:28:04.165300Z",
     "shell.execute_reply": "2025-05-16T23:28:04.164506Z",
     "shell.execute_reply.started": "2025-05-16T23:28:01.921257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_add_cont = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_content.tsv',\n",
    "                          sep='\\t', header=0, index_col=0)\n",
    "df_add_lang = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_language.tsv',\n",
    "                          sep='\\t', header=0, index_col=0)\n",
    "df_add_org = pd.read_csv('/kaggle/input/dress-d/DREsS_CASE_organization.tsv',\n",
    "                          sep='\\t', header=0, index_col=0)\n",
    "df_add_new = pd.read_csv('/kaggle/input/dress-d/DREsS_New.tsv',\n",
    "                          sep='\\t', header=0, index_col=0)\n",
    "df_add_std = pd.read_csv('/kaggle/input/dress-d/DREsS_Std.tsv',\n",
    "                          sep='\\t', header=0, index_col=0)\n",
    "df_add = pd.concat([df_add_cont,\n",
    "                    df_add_lang,\n",
    "                    df_add_org,\n",
    "                    df_add_new,\n",
    "                    df_add_std], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:28:15.528743Z",
     "iopub.status.busy": "2025-05-16T23:28:15.527944Z",
     "iopub.status.idle": "2025-05-16T23:28:15.550992Z",
     "shell.execute_reply": "2025-05-16T23:28:15.550319Z",
     "shell.execute_reply.started": "2025-05-16T23:28:15.528711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>essay</th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "      <th>organization</th>\n",
       "      <th>total</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>@CAPS1 I'm here to prove you wrong and tell yo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smoking should be completely banned at all the...</td>\n",
       "      <td>So how can someone say 'No, you @MONTH1 not li...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>In @CAPS1 middle school, in @PERSON2's dirty a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>One of the most oddest things in life is how p...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>A time when I was patient was when I was helpi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48967</th>\n",
       "      <td>It is important for college students to have a...</td>\n",
       "      <td>I think that it is important for college stude...</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>12.708333</td>\n",
       "      <td>ICNALE EE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48968</th>\n",
       "      <td>Smoking should be completely banned at all the...</td>\n",
       "      <td>I agree with the statement that smoking should...</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.208333</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>10.708333</td>\n",
       "      <td>ICNALE EE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48969</th>\n",
       "      <td>It is important for college students to have a...</td>\n",
       "      <td>In my opinion, I am strongly agree with the id...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>9.583333</td>\n",
       "      <td>ICNALE EE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48970</th>\n",
       "      <td>It is important for college students to have a...</td>\n",
       "      <td>A part time job means to work in separate time...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.208333</td>\n",
       "      <td>ICNALE EE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48971</th>\n",
       "      <td>Smoking should be completely banned at all the...</td>\n",
       "      <td>Despite the fact that the media tells us that ...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>ICNALE EE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      Write about patience. Being patient means that...   \n",
       "1      Smoking should be completely banned at all the...   \n",
       "2      Write about patience. Being patient means that...   \n",
       "3      We all understand the benefits of laughter. Fo...   \n",
       "4      Write about patience. Being patient means that...   \n",
       "...                                                  ...   \n",
       "48967  It is important for college students to have a...   \n",
       "48968  Smoking should be completely banned at all the...   \n",
       "48969  It is important for college students to have a...   \n",
       "48970  It is important for college students to have a...   \n",
       "48971  Smoking should be completely banned at all the...   \n",
       "\n",
       "                                                   essay   content  language  \\\n",
       "0      @CAPS1 I'm here to prove you wrong and tell yo...  1.000000       NaN   \n",
       "1      So how can someone say 'No, you @MONTH1 not li...  1.000000       NaN   \n",
       "2      In @CAPS1 middle school, in @PERSON2's dirty a...  1.000000       NaN   \n",
       "3      One of the most oddest things in life is how p...  1.000000       NaN   \n",
       "4      A time when I was patient was when I was helpi...  1.000000       NaN   \n",
       "...                                                  ...       ...       ...   \n",
       "48967  I think that it is important for college stude...  4.166667  3.958333   \n",
       "48968  I agree with the statement that smoking should...  3.750000  3.208333   \n",
       "48969  In my opinion, I am strongly agree with the id...  3.333333  3.333333   \n",
       "48970  A part time job means to work in separate time...  1.666667  1.875000   \n",
       "48971  Despite the fact that the media tells us that ...  2.500000  3.750000   \n",
       "\n",
       "       organization      total     source  \n",
       "0               NaN        NaN        NaN  \n",
       "1               NaN        NaN        NaN  \n",
       "2               NaN        NaN        NaN  \n",
       "3               NaN        NaN        NaN  \n",
       "4               NaN        NaN        NaN  \n",
       "...             ...        ...        ...  \n",
       "48967      4.583333  12.708333  ICNALE EE  \n",
       "48968      3.750000  10.708333  ICNALE EE  \n",
       "48969      2.916667   9.583333  ICNALE EE  \n",
       "48970      1.666667   5.208333  ICNALE EE  \n",
       "48971      2.916667   9.166667  ICNALE EE  \n",
       "\n",
       "[48972 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_add = pd.read_csv('/kaggle/input/ellipse-combined/asap_1_2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_add = df_add[df_add['essay_set'].isin([1, 2])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_add = df_add['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_add = df_add.rename('full_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:37:33.513931Z",
     "iopub.status.busy": "2025-05-16T23:37:33.513165Z",
     "iopub.status.idle": "2025-05-16T23:37:33.526484Z",
     "shell.execute_reply": "2025-05-16T23:37:33.525732Z",
     "shell.execute_reply.started": "2025-05-16T23:37:33.513904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "texts = df_add['essay']\n",
    "texts = texts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:37:41.744276Z",
     "iopub.status.busy": "2025-05-16T23:37:41.743584Z",
     "iopub.status.idle": "2025-05-16T23:37:41.749567Z",
     "shell.execute_reply": "2025-05-16T23:37:41.748859Z",
     "shell.execute_reply.started": "2025-05-16T23:37:41.744254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pseudo = pd.concat([train_df['full_text'], texts], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:37:43.393047Z",
     "iopub.status.busy": "2025-05-16T23:37:43.392226Z",
     "iopub.status.idle": "2025-05-16T23:37:43.397966Z",
     "shell.execute_reply": "2025-05-16T23:37:43.397251Z",
     "shell.execute_reply.started": "2025-05-16T23:37:43.393021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row.tolist()\n",
    "\n",
    "\n",
    "        inputs = self.tokenizer(text,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=512)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:37:44.613349Z",
     "iopub.status.busy": "2025-05-16T23:37:44.612760Z",
     "iopub.status.idle": "2025-05-16T23:37:44.617212Z",
     "shell.execute_reply": "2025-05-16T23:37:44.616602Z",
     "shell.execute_reply.started": "2025-05-16T23:37:44.613325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "add_dataset = UnlabeledDataset(pseudo, tokenizer)\n",
    "add_loader = DataLoader(add_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:37:47.122167Z",
     "iopub.status.busy": "2025-05-16T23:37:47.121651Z",
     "iopub.status.idle": "2025-05-16T23:59:44.492507Z",
     "shell.execute_reply": "2025-05-16T23:59:44.491572Z",
     "shell.execute_reply.started": "2025-05-16T23:37:47.122140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6585/6585 [21:57<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loop = tqdm(add_loader)\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        preds = model(input_ids, attention_mask)\n",
    "        all_preds.append(preds)\n",
    "all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:59:44.496094Z",
     "iopub.status.busy": "2025-05-16T23:59:44.495849Z",
     "iopub.status.idle": "2025-05-16T23:59:44.499934Z",
     "shell.execute_reply": "2025-05-16T23:59:44.499268Z",
     "shell.execute_reply.started": "2025-05-16T23:59:44.496065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns=[\"Overall\",\n",
    "         \"Cohesion\",\n",
    "         \"Syntax\",\n",
    "         \"Vocabulary\",\n",
    "         \"Phraseology\",\n",
    "         \"Grammar\",\n",
    "         \"Conventions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:59:44.500936Z",
     "iopub.status.busy": "2025-05-16T23:59:44.500693Z",
     "iopub.status.idle": "2025-05-16T23:59:44.613336Z",
     "shell.execute_reply": "2025-05-16T23:59:44.612792Z",
     "shell.execute_reply.started": "2025-05-16T23:59:44.500915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pseudo_df = pd.DataFrame(data=list(zip(*all_preds.T)), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:59:44.614995Z",
     "iopub.status.busy": "2025-05-16T23:59:44.614802Z",
     "iopub.status.idle": "2025-05-16T23:59:44.621533Z",
     "shell.execute_reply": "2025-05-16T23:59:44.620921Z",
     "shell.execute_reply.started": "2025-05-16T23:59:44.614981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pseudo_df['full_text'] = pseudo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T23:59:44.622521Z",
     "iopub.status.busy": "2025-05-16T23:59:44.622206Z",
     "iopub.status.idle": "2025-05-17T00:00:02.353980Z",
     "shell.execute_reply": "2025-05-17T00:00:02.353437Z",
     "shell.execute_reply.started": "2025-05-16T23:59:44.622505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6066778600215912' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6528847515583038' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5361486375331879' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6628443896770477' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6367725431919098' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5985667407512665' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n",
      "/tmp/ipykernel_145/2701176831.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9058404266834259' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    for i in range(len(train_df)):\n",
    "        pseudo_df.loc[i, col] = (pseudo_df.loc[i, col] + train_df.reset_index().loc[i, col]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T00:00:02.354845Z",
     "iopub.status.busy": "2025-05-17T00:00:02.354653Z",
     "iopub.status.idle": "2025-05-17T00:00:02.360312Z",
     "shell.execute_reply": "2025-05-17T00:00:02.359526Z",
     "shell.execute_reply.started": "2025-05-17T00:00:02.354823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row[\"full_text\"].to_list()\n",
    "\n",
    "\n",
    "        inputs = self.tokenizer(text,\n",
    "                                padding=\"max_length\",\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                max_length=512)\n",
    "\n",
    "        scores = torch.tensor(row[columns].values, dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "            \"scores\": scores\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T00:00:02.361568Z",
     "iopub.status.busy": "2025-05-17T00:00:02.361090Z",
     "iopub.status.idle": "2025-05-17T00:00:02.376928Z",
     "shell.execute_reply": "2025-05-17T00:00:02.376193Z",
     "shell.execute_reply.started": "2025-05-17T00:00:02.361543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "combined_dataset = PseudoDataset(pseudo_df, tokenizer)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T00:00:02.378005Z",
     "iopub.status.busy": "2025-05-17T00:00:02.377761Z",
     "iopub.status.idle": "2025-05-17T00:00:04.399742Z",
     "shell.execute_reply": "2025-05-17T00:00:04.399196Z",
     "shell.execute_reply.started": "2025-05-17T00:00:02.377989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_2 = DebertaNHeads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T00:00:04.400580Z",
     "iopub.status.busy": "2025-05-17T00:00:04.400394Z",
     "iopub.status.idle": "2025-05-17T00:00:04.405352Z",
     "shell.execute_reply": "2025-05-17T00:00:04.404718Z",
     "shell.execute_reply.started": "2025-05-17T00:00:04.400565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in model_2.deberta.encoder.layer[:9]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "for param in model_2.deberta.embeddings.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T00:00:04.407306Z",
     "iopub.status.busy": "2025-05-17T00:00:04.407072Z",
     "iopub.status.idle": "2025-05-17T00:00:04.627299Z",
     "shell.execute_reply": "2025-05-17T00:00:04.626738Z",
     "shell.execute_reply.started": "2025-05-17T00:00:04.407291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_training_steps = len(combined_loader) * 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_2.to(device)\n",
    "optimizer = optim.AdamW(model_2.parameters(), lr=4e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:03:21.259475Z",
     "iopub.status.busy": "2025-05-17T08:03:21.259203Z",
     "iopub.status.idle": "2025-05-17T08:03:22.574777Z",
     "shell.execute_reply": "2025-05-17T08:03:22.573877Z",
     "shell.execute_reply.started": "2025-05-17T08:03:21.259457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 2/6585 [00:01<1:10:31,  1.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_145/1467217788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mreg_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "qwk_scores = []\n",
    "best_qwk = -float('inf')\n",
    "\n",
    "model_2.train()\n",
    "for epoch in range(10):\n",
    "    loss_per_epoch = 0\n",
    "    loop = tqdm(combined_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        reg_target = batch[\"scores\"].to(device)\n",
    "        reg_preds = model_2(input_ids, attention_mask)\n",
    "        loss = 0\n",
    "        for i in range(7):\n",
    "            loss += combined_loss(reg_preds[:, i], reg_target[:, i])\n",
    "        loss /= 7\n",
    "        loss_per_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_2.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = loss_per_epoch / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Loss_per_epoch = {avg_loss}')\n",
    "\n",
    "    model_2.eval()\n",
    "    loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            reg_target = batch[\"scores\"].to(device)\n",
    "            reg_preds = model_2(input_ids, attention_mask)\n",
    "            all_preds.append(reg_preds)\n",
    "            all_targets.append(reg_target)\n",
    "    all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "    qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=['Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology', 'Grammar', 'Conventions'])\n",
    "    qwk_scores.append(qwk)\n",
    "    avg_qwk = sum(qwk.values()) / len(qwk)\n",
    "    if avg_qwk - best_qwk > 1e-6:\n",
    "        best_qwk = avg_qwk\n",
    "        print(f\"New best QWK: {best_qwk:.4f}\")\n",
    "        torch.save(model_2.state_dict(), \"/kaggle/working/best_second_model.pth\")\n",
    "    model_2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:03:18.486543Z",
     "iopub.status.busy": "2025-05-17T08:03:18.486266Z",
     "iopub.status.idle": "2025-05-17T08:03:21.258307Z",
     "shell.execute_reply": "2025-05-17T08:03:21.257643Z",
     "shell.execute_reply.started": "2025-05-17T08:03:18.486523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaNHeads(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128002, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (regression_heads): ModuleList(\n",
       "    (0-6): 7 x Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = DebertaNHeads()\n",
    "model_2.load_state_dict(torch.load('/kaggle/working/best_second_model.pth', weights_only=True))\n",
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:03:28.754535Z",
     "iopub.status.busy": "2025-05-17T08:03:28.754277Z",
     "iopub.status.idle": "2025-05-17T08:04:01.265846Z",
     "shell.execute_reply": "2025-05-17T08:04:01.265247Z",
     "shell.execute_reply.started": "2025-05-17T08:03:28.754518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:32<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK for Overall: 0.7446\n",
      "QWK for Cohesion: 0.6384\n",
      "QWK for Syntax: 0.6733\n",
      "QWK for Vocabulary: 0.6582\n",
      "QWK for Phraseology: 0.6680\n",
      "QWK for Grammar: 0.7125\n",
      "QWK for Conventions: 0.6926\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "loop = tqdm(test_loader)\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        target = batch[\"scores\"].to(device)\n",
    "        preds = model_2(input_ids, attention_mask)\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(target)\n",
    "all_preds = torch.cat(all_preds, dim=0).detach().cpu().numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "qwk = evaluate_qwk_for_aspects(all_preds, all_targets, aspects=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7439072,
     "sourceId": 11840206,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7110184,
     "sourceId": 11496551,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
